% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gpt_read.R
\name{gpt_read}
\alias{gpt_read}
\title{Read and process text using GPT}
\usage{
gpt_read(
  chunk_list,
  question = NULL,
  model = "gpt-3.5-turbo",
  temperature = 0.2,
  max_tokens = 100,
  system_message_1 =
    "You are a research assistant trying to answer questions posed based on text you are supplied with. Your goal is to provide answers based on the text provided. If the question is not related to or answered by the text, please only say you cannot find the answer in the text.",
  system_message_2 =
    "You are a content editor who will read the previous responses from the AI and merge them into a single concise response to the question. If they mention that the answer cannot be found in the text for each chunk of text, only say that.",
  num_retries = 5,
  pause_base = 3,
  presence_penalty = 0,
  frequency_penalty = 0,
  api_key
)
}
\arguments{
\item{chunk_list}{A list of text chunks to process.}

\item{question}{The question to ask the model.}

\item{model}{The model to use. Default is "gpt-3.5-turbo".}

\item{temperature}{The temperature parameter for text generation. Default is 0.2.}

\item{max_tokens}{The maximum number of tokens in the generated response. Default is 100.}

\item{system_message_1}{The initial system message to be included in the conversation with the model.}

\item{system_message_2}{The system message for the content editor stage.}

\item{num_retries}{The number of times to retry the API request in case of failure. Default is 5.}

\item{pause_base}{The base pause time between retries. Default is 3.}

\item{presence_penalty}{The presence penalty for text generation. Default is 0.0.}

\item{frequency_penalty}{The frequency penalty for text generation. Default is 0.0.}

\item{api_key}{Character string for the API key assigned to the user by OpenAI}
}
\value{
The generated response from the GPT-3.5 Turbo model.
}
\description{
This function reads a list of text chunks and a question, and uses the GPT-3.5 Turbo model to generate a response
based on the text and question. The function sends requests to the OpenAI API and processes the responses.
}
\examples{
\dontrun{
# Set the path to your file
file <- "~/Desktop/"

# Call the function
text <- parse_text(file)

# api key
api_key <- Sys.getenv('OPENAI_API_KEY')

# Ask question
question <- "what is this article about?"
# Get answer
gpt_read(chunk_list = text, question = question, api_key = api_key) -> response_1
# Review response
print(response_1)

question <- "what is the stupid backoff method?"
gpt_read(chunk_list = text, question = question, api_key = api_key) -> response_2
print(response_2)

question <- "Why do kittens meow?"
gpt_read(chunk_list = text, question = question, api_key = api_key) -> response_3
print(response_3)
}
}
